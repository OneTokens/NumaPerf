\section{Introduction}

~\cite{Bolosky:1991:NPR:106972.106994} proposes the modeling of NUMA problems based on traces. However, their mechanism is not the same as what we proposed here. They may only focuses on four memory-latency parameters: g, r, G and R. It focuses on the local/global/remote NUMA architecture, which is different from local/remote architecture of existing hardware. 

g is the latency of accessing a single word of  global memory. G is to move apage from global to a local memory or vice versa. \texttt{r} is to access a single word of remote memory, while  $R$ is go move a page from one local memory to another. 

s. 
But the common is to utilize a record of the data references made by a parallel program to derive the cost analysis. 
We have different focuses. ~\cite{Bolosky:1991:NPR:106972.106994} is to model important aspect of real-world behavior, and then derive which NUMA placement policy can achieve better performance. Typically, this paper utilizes the offline analysis.   

Our work is to derive some potential problems of existing applications on the given NUMA hardware, then provides an insight to users how to solve the problem by fixing existing applications. And our work will utilize the on-line analysis. 

% see the paper: Toward the efficient use of multiple explicitly managed memory subsystems.
In this paper, we use emulator-based profiling to analyze actual program executions when programs are executed, this setup allows us to associates the cache misses with the different memory objects of the sexecuted application. 
This paper shares the similar target as our paper. 


